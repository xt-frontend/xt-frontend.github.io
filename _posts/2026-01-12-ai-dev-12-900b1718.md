---
layout: post
title: "당신의 LLM에게 '그 버튼을 누르지 마세요'라고 말할 때"
author: ai-assistant
categories: [AI Dev]
tags: [AI, 개발, LLM]
image: assets/images/ai-dev/ai-dev-12-900b1718.jpg
beforetoc: "AI 개발 트렌드 뉴스입니다. 원문: Dev.to"
toc: true
---

LLM(대규모 언어 모델)을 다루다 보면 인간의 언어가 기계에게 전달될 때 예상치 못한 방식으로 해석되는 경우가 많다. 한 개발자는 Gemini에 "새로운 대화 턴을 요약하지 말고 문서 끝에 추가하지 말 것"이라는 명령을 내렸지만, 모델은 정반대로 정확히 그 행동을 수행했다. 이는 단순한 오류가 아니라, AI가 인간의 부정적 명령을 '명령의 중심'으로 받아들이는 구조적 한계였다.  

AI는 '해야 할 일'에 집중하기 위해 설계된 시스템이기 때문에, '아니면 안 된다'는 표현은 오히려 수행 지침으로 재해석될 수 있다. 예를 들어, "이 단어를 사용하지 말라"는 지시는 모델이 그 단어를 의도적으로 회피하도록 강제하기보다는, 해당 단어를 쓰지 않는 다른 표현을 찾아내는 과정을 유도한다. 이는 인간이 흔히 사용하는 '금지'라는 언어가 AI와의 소통에서 무의미해질 수 있음을 보여준다.  

이 경험은 개발자에게 중요한 통찰을 준다. AI를 제어하려면 '어떻게 하지 말 것인가'가 아니라 '무엇을 해야 할 것인가'를 구체적으로 명시하는 것이 효과적이다. 예를 들어, "새로운 정보를 기존 내용과 통합해 자연스럽게 연결하라"는 긍정적 지시는 결과적으로 원하는 행동을 유도하는 데 더 성공적이다.  

이러한 사례는 AI와의 상호작용이 단순한 명령 수행이 아니라, 인간의 언어를 기계가 해석하는 방식을 이해하는 과정임을 상기시킨다. 개발자는 AI의 내부 로직을 인지하고, 명령어를 설계할 때 '어떻게 전달하면 모델이 원하는 방향으로 수렴할지'를 고민해야 한다. 이는 단순한 프롬프트 최적화를 넘어, 인간 중심의 시스템 설계 철학으로 이어질 수 있다.

---
*원문 출처: [Dev.to](https://dev.to/jjdelcerro/cuando-le-dices-a-tu-llm-no-pulses-ese-boton-7m8)*
